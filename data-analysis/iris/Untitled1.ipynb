{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print 'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEFAULT_DICT',\n",
       " 'DEFAULT_DICT_NAME',\n",
       " 'DICT_WRITING',\n",
       " 'PY2',\n",
       " 'Tokenizer',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__license__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__version__',\n",
       " '_compat',\n",
       " '_get_abs_path',\n",
       " '_lcut',\n",
       " '_lcut_all',\n",
       " '_lcut_for_search',\n",
       " '_lcut_for_search_no_hmm',\n",
       " '_pcut',\n",
       " '_pcut_for_search',\n",
       " '_replace_file',\n",
       " 'absolute_import',\n",
       " 'add_word',\n",
       " 'calc',\n",
       " 'cut',\n",
       " 'cut_for_search',\n",
       " 'default_encoding',\n",
       " 'default_logger',\n",
       " 'del_word',\n",
       " 'disable_parallel',\n",
       " 'dt',\n",
       " 'enable_parallel',\n",
       " 'finalseg',\n",
       " 'get_DAG',\n",
       " 'get_FREQ',\n",
       " 'get_dict_file',\n",
       " 'get_module_res',\n",
       " 'initialize',\n",
       " 'iteritems',\n",
       " 'iterkeys',\n",
       " 'itervalues',\n",
       " 'lcut',\n",
       " 'lcut_for_search',\n",
       " 'load_userdict',\n",
       " 'log',\n",
       " 'log_console',\n",
       " 'logging',\n",
       " 'marshal',\n",
       " 'md5',\n",
       " 'os',\n",
       " 'pkg_resources',\n",
       " 'pool',\n",
       " 're',\n",
       " 're_eng',\n",
       " 're_han_cut_all',\n",
       " 're_han_default',\n",
       " 're_skip_cut_all',\n",
       " 're_skip_default',\n",
       " 're_userdict',\n",
       " 'resolve_filename',\n",
       " 'setLogLevel',\n",
       " 'set_dictionary',\n",
       " 'strdecode',\n",
       " 'string_types',\n",
       " 'suggest_freq',\n",
       " 'sys',\n",
       " 'tempfile',\n",
       " 'text_type',\n",
       " 'threading',\n",
       " 'time',\n",
       " 'tokenize',\n",
       " 'unicode_literals',\n",
       " 'user_word_tag_tab']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(jieba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg\n",
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/py/0gqprtwx2wd_zvrlz6hlq2r40000gn/T/jieba.cache\n",
      "Loading model cost 0.412 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欧亚 0.730014270029\n",
      "吉林 0.659038184374\n",
      "置业 0.488713452211\n",
      "万元 0.339272248186\n",
      "增资 0.335824019852\n",
      "4.3 0.254356755381\n",
      "7000 0.254356755381\n",
      "139.13 0.254356755381\n",
      "2013 0.254356755381\n",
      "实现 0.199009799004\n",
      "综合体 0.194803096247\n",
      "经营范围 0.193897572536\n",
      "亿元 0.191442162359\n",
      "在建 0.175418847684\n",
      "全资 0.171801649885\n",
      "注册资本 0.1712441526\n",
      "百货 0.167344600414\n",
      "零售 0.147505711706\n",
      "子公司 0.145960452378\n",
      "营业 0.13920178509\n"
     ]
    }
   ],
   "source": [
    "s = \"此外，公司拟对全资子公司吉林欧亚置业有限公司增资4.3亿元，增资后，吉林欧亚置业注册资本由7000万元增加到5亿元。吉林欧亚置业主要经营范围为房地产开发及百货零售等业务。目前在建吉林欧亚城市商业综合体项目。2013年，实现营业收入0万元，实现净利润-139.13万元。\"\n",
    "for x, w in jieba.analyse.extract_tags(s, withWeight=True):\n",
    "    print '%s %s' % (x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吉林 1.0\n",
      "欧亚 0.996689335418\n",
      "置业 0.643436031309\n",
      "实现 0.589860669286\n",
      "收入 0.43677859948\n",
      "增资 0.409990053128\n",
      "子公司 0.356782959477\n",
      "城市 0.349713836674\n",
      "商业 0.34817220716\n",
      "业务 0.309223099262\n",
      "在建 0.307792916403\n",
      "营业 0.303577704932\n",
      "全资 0.303540981053\n",
      "综合体 0.295808691724\n",
      "注册资本 0.290005194641\n",
      "有限公司 0.280783079858\n",
      "零售 0.278836208612\n",
      "百货 0.278165762845\n",
      "开发 0.26934887793\n",
      "经营范围 0.264276217356\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x, w in jieba.analyse.textrank(s, withWeight=True):\n",
    "    print '%s %s' % (x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Tokenizer in module jieba:\n",
      "\n",
      "class Tokenizer(__builtin__.object)\n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, dictionary=None)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  add_word(self, word, freq=None, tag=None)\n",
      " |      Add a word to dictionary.\n",
      " |      \n",
      " |      freq and tag can be omitted, freq defaults to be a calculated value\n",
      " |      that ensures the word can be cut out.\n",
      " |  \n",
      " |  calc(self, sentence, DAG, route)\n",
      " |  \n",
      " |  check_initialized(self)\n",
      " |  \n",
      " |  cut(self, sentence, cut_all=False, HMM=True)\n",
      " |      The main function that segments an entire sentence that contains\n",
      " |      Chinese characters into seperated words.\n",
      " |      \n",
      " |      Parameter:\n",
      " |          - sentence: The str(unicode) to be segmented.\n",
      " |          - cut_all: Model type. True for full pattern, False for accurate pattern.\n",
      " |          - HMM: Whether to use the Hidden Markov Model.\n",
      " |  \n",
      " |  cut_for_search(self, sentence, HMM=True)\n",
      " |      Finer segmentation for search engines.\n",
      " |  \n",
      " |  del_word(self, word)\n",
      " |      Convenient function for deleting a word.\n",
      " |  \n",
      " |  gen_pfdict(self, f)\n",
      " |  \n",
      " |  get_DAG(self, sentence)\n",
      " |  \n",
      " |  get_dict_file(self)\n",
      " |  \n",
      " |  initialize(self, dictionary=None)\n",
      " |  \n",
      " |  lcut(self, *args, **kwargs)\n",
      " |  \n",
      " |  lcut_for_search(self, *args, **kwargs)\n",
      " |  \n",
      " |  load_userdict(self, f)\n",
      " |      Load personalized dict to improve detect rate.\n",
      " |      \n",
      " |      Parameter:\n",
      " |          - f : A plain text file contains words and their ocurrences.\n",
      " |                Can be a file-like object, or the path of the dictionary file,\n",
      " |                whose encoding must be utf-8.\n",
      " |      \n",
      " |      Structure of dict file:\n",
      " |      word1 freq1 word_type1\n",
      " |      word2 freq2 word_type2\n",
      " |      ...\n",
      " |      Word type may be ignored\n",
      " |  \n",
      " |  set_dictionary(self, dictionary_path)\n",
      " |  \n",
      " |  suggest_freq(self, segment, tune=False)\n",
      " |      Suggest word frequency to force the characters in a word to be\n",
      " |      joined or splitted.\n",
      " |      \n",
      " |      Parameter:\n",
      " |          - segment : The segments that the word is expected to be cut into,\n",
      " |                      If the word should be treated as a whole, use a str.\n",
      " |          - tune : If True, tune the word frequency.\n",
      " |      \n",
      " |      Note that HMM may affect the final result. If the result doesn't change,\n",
      " |      set HMM=False.\n",
      " |  \n",
      " |  tokenize(self, unicode_sentence, mode=u'default', HMM=True)\n",
      " |      Tokenize a sentence and yields tuples of (word, start, end)\n",
      " |      \n",
      " |      Parameter:\n",
      " |          - sentence: the str(unicode) to be segmented.\n",
      " |          - mode: \"default\" or \"search\", \"search\" is for finer segmentation.\n",
      " |          - HMM: whether to use the Hidden Markov Model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(jieba.Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes exactly 1 argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-08bf0a0704d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjieba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextRank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'钢琴曲欣赏100首'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes exactly 1 argument (2 given)"
     ]
    }
   ],
   "source": [
    "jieba.analyse.TextRank('钢琴曲欣赏100首',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "钢琴曲\n",
      "欣赏\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x in jieba.analyse.textrank('钢琴曲欣赏100首', withWeight=False):\n",
    "    print '%s' % (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f= open('test.txt','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\xe5\\x85\\xb3\\xe9\\x94\\xae\\xe6\\x80\\xa7,\\xe8\\xbf\\x99\\xe4\\xba\\x8b\\xe4\\xbb\\x80\\xe4\\xb9\\x88,\\xe6\\x88\\x91\\xe7\\x9a\\x84\\xe5\\xa4\\xa9\\xe5\\x93\\xaa\\n\\xe6\\x88\\x91\\xe6\\x93\\xa6,\\xe4\\xbb\\x80\\xe4\\xb9\\x88\\xe6\\x83\\x85\\xe5\\x86\\xb5,\\xe8\\xbf\\x99\\xe4\\xb8\\xaa\\xe4\\xb8\\x96\\xe7\\x95\\x8c\\xe5\\xa5\\xbd\\xe5\\xa4\\x8d\\xe6\\x9d\\x82'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关键性,这事什么,我的天哪\n",
      "\n",
      "我擦,什么情况,这个世界好复杂\n"
     ]
    }
   ],
   "source": [
    "for i in f:\n",
    "    \n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f= codecs.open('test.txt',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ff=codecs.open('test_a.txt','w',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in f:\n",
    "    ff.write(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00627779E16E7C09B975B2CE13C088CB', '4', '2', '0', '\\xe9\\x92\\xa2\\xe7\\x90\\xb4\\xe6\\x9b\\xb2\\xe6\\xac\\xa3\\xe8\\xb5\\x8f100\\xe9\\xa6\\x96', '\\xe4\\xb8\\x80\\xe4\\xb8\\xaa\\xe6\\x9c\\x88\\xe7\\x9a\\x84\\xe5\\xae\\x9d\\xe5\\xae\\x9d\\xe7\\x9c\\xbc\\xe7\\x9d\\xab\\xe6\\xaf\\x9b\\xe9\\x82\\xa3\\xe4\\xb9\\x88\\xe6\\x98\\xaf\\xe9\\xbb\\x84\\xe8\\x89\\xb2', '\\xe5\\xae\\x9d\\xe5\\xae\\x9d\\xe5\\x8f\\xb3\\xe7\\x9c\\xbc\\xe6\\x9c\\x89\\xe7\\x9c\\xbc\\xe5\\xb1\\x8e', '\\xe5\\xb0\\x8f\\xe5\\x84\\xbf\\xe6\\x8a\\xbd\\xe6\\x90\\x90\\xe6\\x80\\x8e\\xe4\\xb9\\x88\\xe5\\x8a\\x9e', '\\xe5\\x89\\x96\\xe8\\x85\\xb9\\xe4\\xba\\xa7\\xe5\\x90\\x8e\\xe5\\x88\\x80\\xe5\\x8f\\xa3\\xe4\\xb8\\x8a\\xe6\\x9c\\x89\\xe7\\xba\\xbf\\xe5\\xa4\\xb4', '\\xe5\\xb1\\x9e\\xe7\\xbe\\x8a\\xe5\\x92\\x8c\\xe5\\xb1\\x9e\\xe9\\xb8\\xa1\\xe7\\x9a\\x84\\xe9\\x85\\x8d\\xe5\\x90\\x97']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('test.csv','r') as ipt, codecs.open('test_after.csv','w') as opt:\n",
    "        opt.write('\\xEF\\xBB\\xBF')\n",
    "        opt.write('id,age,gender,education,query_list\\n')\n",
    "        for i in ipt.readlines():\n",
    "            seq_list = i.split()\n",
    "            print seq_list\n",
    "            opt.write(repr(seq_list))\n",
    "except IOError as e:\n",
    "    print 'file error',e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00627779E16E7C09B975B2CE13C088CB     4     2     0     钢琴曲欣赏100首     一个月的宝宝眼睫毛那么是黄色     宝宝右眼有眼屎    小儿抽搐怎么办    剖腹产后刀口上有线头    属羊和属鸡的配吗\n",
      "00627779E16E712312313133333088CB     1     2     6     十万个为什么     今天的天气     宝贝计划\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import csv  \n",
    "import re  \n",
    "import time  \n",
    "import io  \n",
    "#********************************************  \n",
    "class ReportWriter():  \n",
    "   def __init__(self, item, filename):  \n",
    "      # item is a list to be written into a CSV file  \n",
    "      self.value = item  \n",
    "      self.filename = filename  \n",
    "      self.wirteFormat()    #参见说明1  \n",
    "  \n",
    "   # parameter 'value' need to be str  \n",
    "   def updateValue(self, value, idx = -1):  \n",
    "      if idx>=0:  \n",
    "         self.value[idx] = value#.encode('UTF-8')  \n",
    "      else:  \n",
    "         self.value = ','.join(value.split())#.encode('UTF-8')  \n",
    "  \n",
    "   def wirteFormat(self):  \n",
    "      fw = io.open(self.filename, 'w', encoding = 'utf-8')      \n",
    "      fw.write(unicode(\"\\xEF\\xBB\\xBF\", \"utf-8\"))     #参见说明2  \n",
    "      fw.write(unicode('id,age,gender,education,query_list\\n','utf-8'))\n",
    "   def writeFile(self):  \n",
    "      #print type(self.value)  \n",
    "      fw = io.open(self.filename, 'a', encoding = 'utf-8')     #参见说明3  \n",
    "      fw.write(unicode(self.value, \"utf-8\"))    #参见说明4  \n",
    "      fw.close()  \n",
    "  \n",
    "if ( __name__ == \"__main__\"):  \n",
    "  \n",
    "   filename = 'a.csv'    \n",
    "   data = '中文'   # -1- 在代码文件中定义的包含中文的字符变量没有乱码的问题。  \n",
    "     \n",
    "   f = ReportWriter(data, filename)  \n",
    "   #f.writeFile()   #去掉前面的注释运行可以看到 data 变量被正确写入到csv文件，无乱码  \n",
    "  \n",
    "   fr = open('test.csv', 'r')    # -2- 打开xml 文件   \n",
    "   content = fr.read()        # 读取文件内容  \n",
    "   print(content)           # 打印结果正常，无乱码  \n",
    "   f.updateValue(content)    # updateValue() 函数用从xml文件中读到的字符更新ReportWriter类的实例f的value变量  \n",
    "  \n",
    "   f.writeFile()              # 接着调用writeFile()函数将从xml文件中读到的字符写入a.csv  \n",
    "   print('done')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to chenye277@126.com and will expire on September 08, 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1475250934.log\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"00627779E16E7C09B975B2CE13C088CB,4,2,0,钢琴曲欣赏100首,一个月的宝宝眼睫毛那么是黄色,宝宝右眼有眼屎,小儿抽搐怎么办,剖腹产后刀口上有线头,属羊和属鸡的配吗\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"00627779E16E7C09B975B2CE13C088CB,4,2,0,钢琴曲欣赏100首,一个月的宝宝眼睫毛那么是黄色,宝宝右眼有眼屎,小儿抽搐怎么办,剖腹产后刀口上有线头,属羊和属鸡的配吗\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>1 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "1 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/Crayon_277/Develop/Project/Python/data-analysis/iris/a.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/Crayon_277/Develop/Project/Python/data-analysis/iris/a.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 0 lines in 0.021443 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 0 lines in 0.021443 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient number of rows to perform type inference\n",
      "Could not detect types. Using str for each column.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Unable to parse line \"00627779E16E7C09B975B2CE13C088CB,4,2,0,钢琴曲欣赏100首,一个月的宝宝眼睫毛那么是黄色,宝宝右眼有眼屎,小儿抽搐怎么办,剖腹产后刀口上有线头,属羊和属鸡的配吗\"</pre>"
      ],
      "text/plain": [
       "Unable to parse line \"00627779E16E7C09B975B2CE13C088CB,4,2,0,钢琴曲欣赏100首,一个月的宝宝眼睫毛那么是黄色,宝宝右眼有眼屎,小儿抽搐怎么办,剖腹产后刀口上有线头,属羊和属鸡的配吗\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>1 lines failed to parse correctly</pre>"
      ],
      "text/plain": [
       "1 lines failed to parse correctly"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/Crayon_277/Develop/Project/Python/data-analysis/iris/a.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/Crayon_277/Develop/Project/Python/data-analysis/iris/a.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 0 lines in 0.00758 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 0 lines in 0.00758 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sf = graphlab.SFrame('a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">﻿id</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">age</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">gender</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">education</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">query_list</th>\n",
       "    </tr>\n",
       "</table>\n",
       "[0 rows x 5 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\t﻿id\tstr\n",
       "\tage\tstr\n",
       "\tgender\tstr\n",
       "\teducation\tstr\n",
       "\tquery_list\tstr\n",
       "\n",
       "Rows: 0\n",
       "\n",
       "Data:\n",
       "\t[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [gl-env]",
   "language": "python",
   "name": "Python [gl-env]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
